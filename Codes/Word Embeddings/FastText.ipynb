{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c4b17b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65c4b17b",
        "outputId": "2b074796-a501-4b54-bebe-6553f748e879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3165480 sha256=621db7815baebd4f7448d8dcbdb7f4b4ed8910642e6fd02014dea0cc7a5dc156\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "446f148c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "446f148c",
        "outputId": "7fac063c-4d49-4530-fe08-591cacb27dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import logging\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models.fasttext import FastText\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import csv\n",
        "import warnings\n",
        "warnings.filterwarnings ('ignore')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2818af5",
      "metadata": {
        "id": "e2818af5"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv('GitterCom.csv', header=0, encoding='UTF8')\n",
        "#df['message'].to_csv('alice.txt', sep=\"\\n\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtk3SP9LjxeU",
        "outputId": "fd535e71-f0b1-4216-c683-7bb159ec721a"
      },
      "id": "Rtk3SP9LjxeU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a42ef2d",
      "metadata": {
        "id": "1a42ef2d"
      },
      "outputs": [],
      "source": [
        "sample = open(\"/content/gdrive/My Drive/Gitter_Dataset/alice.txt\", \"r\",encoding=\"utf8\")\n",
        "s = sample.read()\n",
        "f = s.replace(\"\\n\", \" \")\n",
        "\n",
        "data = []\n",
        "for i in sent_tokenize(f):\n",
        "\ttemp = []\n",
        "\n",
        "\t# tokenize the sentence into words\n",
        "\tfor j in word_tokenize(i):\n",
        "\t\ttemp.append(j.lower())\n",
        "\n",
        "\tdata.append(temp)\n",
        "\n",
        "model = FastText(data, min_count = 1, size = 100, window = 5, sg = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41061b7f",
      "metadata": {
        "id": "41061b7f"
      },
      "outputs": [],
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS =nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def clean_text(text):\n",
        "    if type(text)==str:\n",
        "\n",
        "        text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "        text = text.lower() # lowercase text\n",
        "        text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "        text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "        text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "        return text\n",
        "    return \"\"\n",
        "def wordprint(words,model1):\n",
        "    all_words, mean = set(), []\n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in model1.wv.vocab:\n",
        "            a=np.array(model1[word])\n",
        "            mean.append(a)\n",
        "    if not mean:\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(100,)\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "171a77c7",
      "metadata": {
        "id": "171a77c7"
      },
      "outputs": [],
      "source": [
        "def  word_averaging_listn(wv, text_list):\n",
        "    return np.vstack([wordprint(post,wv) for post in text_list ])\n",
        "\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7af8cc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7af8cc2",
        "outputId": "7e760ed4-9de2-477c-b248-ad4f65bfa762"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9959"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "fname='/content/gdrive/My Drive/Gitter_Dataset/GitterCom'+'.csv'\n",
        "df = pd.read_csv(fname,encoding='UTF8')\n",
        "df.drop([581, 2102, 4858, 6417], axis=0, inplace=True)\n",
        "\n",
        "non_string = []\n",
        "for i, row in df.iterrows():\n",
        "    res = ((type(row['message']) != str) or (type(row['Purpose']) != str) or (type(row['Category']) != str) or (type(row['Subcategory']) != str))\n",
        "    if res:\n",
        "        non_string.append(i)\n",
        "\n",
        "df.drop(non_string, axis=0, inplace=True)\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a2e2417",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a2e2417",
        "outputId": "6d53b12c-5aad-4eb9-f04d-e09eca466289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             message    Purpose  \\\n",
            "0  hi team recently upgraded cucumberjvm version ...  team wide   \n",
            "1  exception thread main javalangnosuchmethoderro...  team wide   \n",
            "2  amit007 looks like inconsistent cucumber jar v...  team wide   \n",
            "3                        github trying replace irc p  team wide   \n",
            "4  aslakhellesoy thanks seems like using older ve...  team wide   \n",
            "5  hi one question friends starting project studi...  team wide   \n",
            "6  danon9111 integrate cucumber another testing f...  team wide   \n",
            "7  aslakhellesoy reading cucumber book found code...  team wide   \n",
            "8                 sidkiyassine call methods directly  team wide   \n",
            "9  intergrated cucumber+appium https githubcom pr...  team wide   \n",
            "\n",
            "        Category                          Subcategory  \n",
            "0        dev-ops  development operation notifications  \n",
            "1        dev-ops  development operation notifications  \n",
            "2  communication         communication with teammates  \n",
            "3  communication         communication with teammates  \n",
            "4  communication         communication with teammates  \n",
            "5        dev-ops                             team q&a  \n",
            "6        dev-ops                             team q&a  \n",
            "7        dev-ops                             team q&a  \n",
            "8        dev-ops                             team q&a  \n",
            "9        dev-ops  development operation notifications  \n"
          ]
        }
      ],
      "source": [
        "df.drop(['Channel','messageId','time','user'],axis=1,inplace=True)\n",
        "df['Category']=df['Category'].str.lower()\n",
        "df['Purpose']=df['Purpose'].str.lower()\n",
        "df['Subcategory']=df['Subcategory'].str.lower()\n",
        "df['message'] = df['message'].apply(clean_text)\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68578e6b",
      "metadata": {
        "id": "68578e6b"
      },
      "outputs": [],
      "source": [
        "comtdata=df\n",
        "test_tokenized = comtdata.apply(lambda r: w2v_tokenize_text(r['message']), axis=1).values\n",
        "X_comtdata_average1 = word_averaging_listn(model, test_tokenized)\n",
        "fname='7'+'.csv'   #fasttext\n",
        "np.savetxt(fname,X_comtdata_average1, delimiter=',', fmt='%f')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vtn8gG4v-dYL"
      },
      "id": "Vtn8gG4v-dYL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}