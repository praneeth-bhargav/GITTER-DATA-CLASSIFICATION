{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9742d109",
      "metadata": {
        "id": "9742d109"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import gensim\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e61186a",
      "metadata": {
        "id": "2e61186a"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('GitterCom.csv', header=0, encoding='UTF8')\n",
        "df['message'].to_csv('alice.txt', sep=\"\\n\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a39be2",
      "metadata": {
        "id": "a6a39be2"
      },
      "outputs": [],
      "source": [
        "# Hide all the warnings in jupyter notebook\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings ('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad8ea3b",
      "metadata": {
        "id": "8ad8ea3b"
      },
      "outputs": [],
      "source": [
        "sample = open(\"alice.txt\", \"r\",encoding=\"utf8\")\n",
        "s = sample.read()\n",
        "f = s.replace(\"\\n\", \" \")\n",
        "\n",
        "data = []\n",
        "for i in sent_tokenize(f):\n",
        "\ttemp = []\n",
        "\n",
        "\t# tokenize the sentence into words\n",
        "\tfor j in word_tokenize(i):\n",
        "\t\ttemp.append(j.lower())\n",
        "\n",
        "\tdata.append(temp)\n",
        "model1 = gensim.models.Word2Vec(data, min_count = 1,vector_size=100, window = 5)\n",
        "#<---deprecated model1 = gensim.models.Word2Vec(data, min_count = 1,size=100, window = 5)-------->deprecated#\n",
        "\n",
        "model2 = gensim.models.Word2Vec(data, min_count = 1,vector_size=100, window = 5, sg = 1)\n",
        "\n",
        "#<---deprecated model2 = gensim.models.Word2Vec(data, min_count = 1,size=100,window = 5, sg = 1-------->deprecated#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6da522",
      "metadata": {
        "id": "5c6da522"
      },
      "outputs": [],
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS =nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def clean_text(text):\n",
        "    if type(text)==str:\n",
        "\n",
        "        text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "        text = text.lower() # lowercase text\n",
        "        text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "        text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "        text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "        return text\n",
        "    return \"\"\n",
        "def wordprint(words,model1):\n",
        "    all_words, mean = set(), []\n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in model1.wv.key_to_index:\n",
        "            a=np.array(model1.wv[word])\n",
        "            mean.append(a)\n",
        "    if not mean:\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(100,)\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036aba12",
      "metadata": {
        "id": "036aba12"
      },
      "outputs": [],
      "source": [
        "def  word_averaging_listn(wv, text_list):\n",
        "    return np.vstack([wordprint(post,wv) for post in text_list ])\n",
        "\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db76827",
      "metadata": {
        "id": "5db76827",
        "outputId": "9d9bf70e-5460-4e7d-e52c-657b334c7bc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9959"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "fname='GitterCom'+'.csv'\n",
        "df = pd.read_csv(fname,encoding='UTF8')\n",
        "df.drop([581, 2102, 4858, 6417], axis=0, inplace=True)\n",
        "\n",
        "non_string = []\n",
        "for i, row in df.iterrows():\n",
        "    res = ((type(row['message']) != str) or (type(row['Purpose']) != str) or (type(row['Category']) != str) or (type(row['Subcategory']) != str))\n",
        "    if res:\n",
        "        non_string.append(i)\n",
        "\n",
        "df.drop(non_string, axis=0, inplace=True)\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd533e1",
      "metadata": {
        "id": "efd533e1",
        "outputId": "7ea2330a-f08a-4cb2-e827-27743731460a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             message    Purpose  \\\n",
            "0  hi team recently upgraded cucumberjvm version ...  team wide   \n",
            "1  exception thread main javalangnosuchmethoderro...  team wide   \n",
            "2  amit007 looks like inconsistent cucumber jar v...  team wide   \n",
            "3                        github trying replace irc p  team wide   \n",
            "4  aslakhellesoy thanks seems like using older ve...  team wide   \n",
            "5  hi one question friends starting project studi...  team wide   \n",
            "6  danon9111 integrate cucumber another testing f...  team wide   \n",
            "7  aslakhellesoy reading cucumber book found code...  team wide   \n",
            "8                 sidkiyassine call methods directly  team wide   \n",
            "9  intergrated cucumber+appium https githubcom pr...  team wide   \n",
            "\n",
            "        Category                          Subcategory  \n",
            "0        dev-ops  development operation notifications  \n",
            "1        dev-ops  development operation notifications  \n",
            "2  communication         communication with teammates  \n",
            "3  communication         communication with teammates  \n",
            "4  communication         communication with teammates  \n",
            "5        dev-ops                             team q&a  \n",
            "6        dev-ops                             team q&a  \n",
            "7        dev-ops                             team q&a  \n",
            "8        dev-ops                             team q&a  \n",
            "9        dev-ops  development operation notifications  \n"
          ]
        }
      ],
      "source": [
        "df.drop(['Channel','messageId','time','user'],axis=1,inplace=True)\n",
        "df['Category']=df['Category'].str.lower()\n",
        "df['Purpose']=df['Purpose'].str.lower()\n",
        "df['Subcategory']=df['Subcategory'].str.lower()\n",
        "df['message'] = df['message'].apply(clean_text)\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e725d686",
      "metadata": {
        "id": "e725d686"
      },
      "outputs": [],
      "source": [
        "comtdata=df\n",
        "test_tokenized = comtdata.apply(lambda r: w2v_tokenize_text(r['message']), axis=1).values\n",
        "X_comtdata_average1 = word_averaging_listn(model1,test_tokenized)\n",
        "fname='1'+'.csv'   #cbow\n",
        "np.savetxt(fname,X_comtdata_average1, delimiter=',', fmt='%f')\n",
        "X_comtdata_average1 = word_averaging_listn(model2,test_tokenized)\n",
        "fname='2'+'.csv'   #skg\n",
        "np.savetxt(fname,X_comtdata_average1, delimiter=',', fmt='%f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522eb677",
      "metadata": {
        "id": "522eb677"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}